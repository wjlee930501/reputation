"""SoV ì—”ì§„ â€” ì¿¼ë¦¬ ìë™ ìƒì„±Â·ë°œì†¡Â·íŒŒì‹±Â·ê³„ì‚°"""
import asyncio
import json
import logging
from itertools import product

import httpx
from openai import AsyncOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential

from app.core.config import settings

logger = logging.getLogger(__name__)
openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

QUERY_TEMPLATES = [
    "{region} {keyword} ì˜ ë³´ëŠ” ë³‘ì› ì¶”ì²œí•´ì¤˜",
    "{region} {specialty} ì–´ë””ê°€ ì¢‹ì•„",
    "{sub_region} {keyword} ì˜í•˜ëŠ” ê³³",
    "{region} {specialty} ì „ë¬¸ì˜ ì¶”ì²œ",
    "{keyword} ìˆ˜ìˆ  {region} ì–´ëŠ ë³‘ì›ì´ ì¢‹ì•„?",
    "{region} {keyword} ì¹˜ë£Œ ì˜í•˜ëŠ” ë³‘ì›",
    "{keyword} ì¦ìƒ {region}ì—ì„œ ì¹˜ë£Œ ì˜í•˜ëŠ” ê³³",
    "{region} {specialty} ë³‘ì› ì–´ë””ê°€ ì¢‹ì€ì§€ ë¹„êµí•´ì¤˜",
    "{keyword} ì¹˜ë£Œ ë¹„ìš©ì´ ì–¼ë§ˆë‚˜ ë“œëŠ”ì§€ ì•Œë ¤ì¤˜",
]

PARSE_PROMPT = """\
ë‹¤ìŒ AI ë‹µë³€ì—ì„œ "{hospital_name}"ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ ë¶„ì„í•˜ë¼.
ë³‘ì›ëª… ì¶•ì•½í˜•Â·ë³€í˜•ë„ ì–¸ê¸‰ìœ¼ë¡œ ì¸ì •í•œë‹¤.

[ë‹µë³€]
{response}

ë°˜ë“œì‹œ ì•„ë˜ JSONë§Œ ì¶œë ¥:
{{"is_mentioned": true/false, "mention_rank": null ë˜ëŠ” ì •ìˆ˜, "sentiment": "positive"/"neutral"/"negative"/null, "mention_context": "ì–¸ê¸‰ ë¬¸ì¥ ë˜ëŠ” null"}}"""


def generate_query_matrix(region: list[str], specialties: list[str], keywords: list[str]) -> list[str]:
    # ğŸ”´ CRITICAL fix: empty inputs cause product() to yield zero combinations,
    # returning an empty list. Without this guard, V0 report runs with 0 queries
    # and produces a meaningless 0% SoV result silently.
    if not keywords or not specialties:
        logger.warning(
            f"generate_query_matrix called with empty inputs: "
            f"region={region}, specialties={specialties}, keywords={keywords}. "
            f"Returning empty query list."
        )
        return []

    queries = set()
    main_region = region[0] if region else ""
    sub_region = region[1] if len(region) > 1 else main_region
    for template, keyword, specialty in product(QUERY_TEMPLATES, keywords, specialties):
        q = template.format(region=main_region, sub_region=sub_region, keyword=keyword, specialty=specialty)
        queries.add(q)
    return list(queries)


@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
async def _query_chatgpt(query: str) -> str:
    response = await openai_client.chat.completions.create(
        model=settings.OPENAI_MODEL_QUERY,
        messages=[
            {"role": "system", "content": "ì§€ì—­ ë³‘ì› ì •ë³´ë¥¼ ì˜ ì•„ëŠ” ì˜ë£Œ ì •ë³´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë³‘ì› ì´ë¦„ì„ í¬í•¨í•´ ë‹µë³€í•˜ì„¸ìš”."},
            {"role": "user", "content": query},
        ],
        temperature=1.0,
        max_tokens=800,
    )
    return response.choices[0].message.content or ""


@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
async def _query_perplexity(query: str) -> str:
    if not settings.PERPLEXITY_API_KEY:
        return ""
    async with httpx.AsyncClient(timeout=30) as client:
        r = await client.post(
            "https://api.perplexity.ai/chat/completions",
            headers={"Authorization": f"Bearer {settings.PERPLEXITY_API_KEY}"},
            json={
                "model": settings.PERPLEXITY_MODEL,
                "messages": [{"role": "user", "content": query}],
                "temperature": 1.0, "max_tokens": 800,
            },
        )
        r.raise_for_status()
        return r.json()["choices"][0]["message"]["content"]


async def _parse_mention(hospital_name: str, response_text: str) -> dict:
    if not response_text.strip():
        return {"is_mentioned": False, "mention_rank": None, "sentiment": None, "mention_context": None}
    # ë¹ ë¥¸ ì‚¬ì „ í•„í„°
    if hospital_name[:2] not in response_text:
        return {"is_mentioned": False, "mention_rank": None, "sentiment": None, "mention_context": None}

    result = await openai_client.chat.completions.create(
        model=settings.OPENAI_MODEL_PARSE,
        messages=[{"role": "user", "content": PARSE_PROMPT.format(
            response=response_text[:3000], hospital_name=hospital_name
        )}],
        temperature=0, max_tokens=200,
        response_format={"type": "json_object"},
    )
    try:
        return json.loads(result.choices[0].message.content or "{}")
    except Exception:
        return {"is_mentioned": False, "mention_rank": None, "sentiment": None, "mention_context": None}


async def run_single_query(hospital_name: str, query_text: str, platform: str, repeat_count: int) -> list[dict]:
    sem = asyncio.Semaphore(3)
    query_fn = _query_chatgpt if platform == "chatgpt" else _query_perplexity

    async def single():
        async with sem:
            try:
                raw = await query_fn(query_text)
                parsed = await _parse_mention(hospital_name, raw)
                return {**parsed, "raw_response": raw}
            except Exception as e:
                logger.error(f"Query failed: {e}")
                return {"is_mentioned": False, "mention_rank": None, "sentiment": None, "mention_context": None, "raw_response": ""}

    return list(await asyncio.gather(*[single() for _ in range(repeat_count)]))


def calculate_sov(results: list[dict]) -> float:
    if not results:
        return 0.0
    return round(sum(1 for r in results if r.get("is_mentioned")) / len(results) * 100, 2)
